{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08c8bad1-bcae-45c6-a2e6-3f45a8bc85b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# SECTION 0 — Setup, paths, NSS curve\n",
    "# ======================================\n",
    "import os, json, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timezone\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import qmc\n",
    "import numba as nb\n",
    "\n",
    "EXPORT = Path(\"export\")\n",
    "EXPORT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CHAIN_FILE = \"chain_data.csv\"       # dataset\n",
    "META_FILE  = \"mstr_panel_meta.json\" # S0, spot_ts, ticker, q\n",
    "\n",
    "# ------- NSS (OLS) -------\n",
    "def _nss_basis(m, tau1, tau2):\n",
    "    m = np.asarray(m, float)\n",
    "    def B1(x,t):\n",
    "        xt = x/t\n",
    "        den = np.where(xt==0.0, 1.0, xt)\n",
    "        return (1.0 - np.exp(-xt)) / den\n",
    "    def B2(x,t):\n",
    "        xt = x/t\n",
    "        den = np.where(xt==0.0, 1.0, xt)\n",
    "        return (1.0 - np.exp(-xt)) / den - np.exp(-xt)\n",
    "    return B1(m, tau1), B2(m, tau1), B2(m, tau2)\n",
    "\n",
    "def calibrate_nss_ols(maturities, y):\n",
    "    maturities = np.asarray(maturities, float)\n",
    "    y = np.asarray(y, float)\n",
    "    def obj(z):\n",
    "        tau1, tau2 = np.exp(z[0]), np.exp(z[1])\n",
    "        B1, B2, B3 = _nss_basis(maturities, tau1, tau2)\n",
    "        X = np.column_stack([np.ones_like(maturities), B1, B2, B3])\n",
    "        beta, *_ = np.linalg.lstsq(X, y, rcond=None)\n",
    "        r = y - X @ beta\n",
    "        return float(r @ r)\n",
    "    z0 = np.log([1.5, 3.0])\n",
    "    res = minimize(obj, z0, method=\"Nelder-Mead\")\n",
    "    tau1, tau2 = np.exp(res.x[0]), np.exp(res.x[1])\n",
    "    B1, B2, B3 = _nss_basis(maturities, tau1, tau2)\n",
    "    X = np.column_stack([np.ones_like(maturities), B1, B2, B3])\n",
    "    beta, *_ = np.linalg.lstsq(X, y, rcond=None)\n",
    "    def nss_yield(m):\n",
    "        m = np.asarray(m, float)\n",
    "        b1, b2, b3 = _nss_basis(m, tau1, tau2)\n",
    "        Xm = np.column_stack([np.ones_like(m), b1, b2, b3])\n",
    "        return Xm @ beta\n",
    "    return nss_yield, {\"beta\":beta, \"tau1\":tau1, \"tau2\":tau2}\n",
    "\n",
    "# curva input (fissa)\n",
    "_y_m = np.array([1/12, 1.5/12, 2/12, 3/12, 4/12, 6/12, 1, 2, 3, 5, 7, 10, 20, 30])\n",
    "_y_y = np.array([4.18, 4.15, 4.08, 4.00, 3.95, 3.79, 3.56, 3.46, 3.47, 3.59, 3.78, 4.02, 4.58, 4.60])/100\n",
    "nss_yield, _ = calibrate_nss_ols(_y_m, _y_y)\n",
    "r_curve = lambda T: float(np.asarray(nss_yield(np.array([T])))[0])\n",
    "\n",
    "# meta\n",
    "with open(META_FILE, \"r\") as f:\n",
    "    meta = json.load(f)\n",
    "S0     = float(meta.get(\"S0\", 100.0))\n",
    "spot_ts= meta.get(\"spot_ts\")\n",
    "ticker = str(meta.get(\"ticker\",\"TICKER\")).upper()\n",
    "q_div  = float(meta.get(\"q\", 0.0))\n",
    "\n",
    "BASE_DATE = datetime.fromisoformat(spot_ts.replace(\"Z\",\"+00:00\")).astimezone(timezone.utc).replace(tzinfo=None)\n",
    "def _yf(d: datetime, base: datetime = BASE_DATE) -> float:\n",
    "    return (d - base).days/365.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7bc5977-96bf-499b-9be4-51dbe1b595f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# SECTION 1 — Build cleaned chain with r(T) from NSS\n",
    "# ======================================================\n",
    "def _yf_365(start_ts, end_ts):\n",
    "    s = pd.to_datetime(start_ts, utc=True, errors=\"coerce\")\n",
    "    e = pd.to_datetime(end_ts,   utc=True, errors=\"coerce\")\n",
    "    return (e - s).total_seconds()/(365*24*3600)\n",
    "\n",
    "df_raw = pd.read_csv(CHAIN_FILE)\n",
    "lc = {c.lower(): c for c in df_raw.columns}\n",
    "def pick(cands):\n",
    "    for c in cands:\n",
    "        if c in lc: return lc[c]\n",
    "    return None\n",
    "\n",
    "# filtra call se presente\n",
    "col_right = pick([\"right\",\"optiontype\",\"putcall\",\"type\",\"cp\"])\n",
    "if col_right is not None:\n",
    "    df_raw = df_raw[df_raw[col_right].astype(str).str.upper().str.startswith(\"C\")]\n",
    "\n",
    "colK  = pick([\"k\",\"strike\",\"strk\",\"strikeprice\",\"strike_price\"])\n",
    "colPx = pick([\"mid\",\"mark\",\"price\",\"close\",\"last\",\"theo\",\"settlement\",\"settle\"])\n",
    "if colPx is None:\n",
    "    cb = pick([\"bid\",\"call_bid\",\"bestbid\"]); ca = pick([\"ask\",\"call_ask\",\"bestask\",\"offer\",\"ofr\"])\n",
    "    if cb and ca:\n",
    "        df_raw[\"__mid__\"] = (pd.to_numeric(df_raw[cb],errors=\"coerce\")+pd.to_numeric(df_raw[ca],errors=\"coerce\"))/2\n",
    "        colPx=\"__mid__\"\n",
    "colT  = pick([\"t\",\"tau\",\"ttm\",\"maturity\",\"time_to_maturity\"])\n",
    "colExp= None if colT else pick([\"expiry\",\"expiration\",\"maturitydate\",\"expirationdate\",\"exp_date\",\"expirydate\",\"expiry_iso\"])\n",
    "\n",
    "if colK is None or colPx is None or (colT is None and colExp is None):\n",
    "    raise KeyError(\"Colonne richieste mancanti in chain_data.csv\")\n",
    "\n",
    "df = df_raw.copy()\n",
    "if colT is None:\n",
    "    exp = df[colExp].astype(str)\n",
    "    m8  = exp.str.fullmatch(r\"\\d{8}\")\n",
    "    exp.loc[m8]  = exp.loc[m8]  + \" 16:00\"\n",
    "    m10 = exp.str.fullmatch(r\"\\d{4}-\\d{2}-\\d{2}\")\n",
    "    exp.loc[m10] = exp.loc[m10] + \" 16:00\"\n",
    "    df[\"T\"] = exp.apply(lambda x: _yf_365(spot_ts, x))\n",
    "else:\n",
    "    df = df.rename(columns={colT:\"T\"})\n",
    "df = df.rename(columns={colK:\"K\", colPx:\"close\"})\n",
    "\n",
    "df = df[[\"T\",\"K\",\"close\"]].apply(pd.to_numeric, errors=\"coerce\").dropna().astype(float)\n",
    "df = df[(df[\"T\"]>0) & (df[\"K\"]>0) & (df[\"close\"]>0)]\n",
    "df = df[df[\"close\"]>=1.0].copy()  # stabilità\n",
    "\n",
    "df[\"r\"] = df[\"T\"].apply(r_curve)\n",
    "df = df.sort_values([\"T\",\"K\"]).reset_index(drop=True)\n",
    "df.to_csv(EXPORT/\"chain_clean.csv\", index=False, float_format=\"%.10f\")\n",
    "\n",
    "# variabili vettoriali per calibrazione\n",
    "K  = df[\"K\"].values\n",
    "T  = df[\"T\"].values\n",
    "rr = df[\"r\"].values\n",
    "qq = np.full_like(rr, q_div, dtype=float)\n",
    "Pm = df[\"close\"].values\n",
    "EPS = 1e-12\n",
    "den = np.maximum(Pm, EPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45a4702a-9655-4c12-b44e-9a1fa442a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# SECTION 2 — BS + Jump-to-Default calibration\n",
    "#           Fix: funzioni vettoriali senza ambiguità\n",
    "# ======================================================\n",
    "def bs_call_vec(S0, K, T, r, q, sigma):\n",
    "    K = np.asarray(K, float); T=np.asarray(T,float); r=np.asarray(r,float); q=float(q)\n",
    "    s = float(sigma)\n",
    "    sqrtT = np.sqrt(np.maximum(T, 0.0))\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        d1 = (np.log(S0/K) + (r - q + 0.5*s*s)*T) / (s*sqrtT)\n",
    "    d1 = np.where((s<=0) | (T<=0), np.inf, d1)\n",
    "    d2 = d1 - s*sqrtT\n",
    "    price = S0*np.exp(-q*T)*norm.cdf(d1) - K*np.exp(-r*T)*norm.cdf(d2)\n",
    "    intrinsic = np.maximum(S0 - K, 0.0)\n",
    "    price = np.where(T<=0, intrinsic, price)\n",
    "    return price\n",
    "\n",
    "def rel_metrics(P):\n",
    "    e = (P-Pm)/den\n",
    "    sse  = float(np.sum(e*e))\n",
    "    rmse = float(np.sqrt(np.mean(e*e)))\n",
    "    mae  = float(np.mean(np.abs(e)))\n",
    "    bias = float(np.mean(e))\n",
    "    return sse, rmse, mae, bias\n",
    "\n",
    "# griglia sigma, lambda\n",
    "SIGMA_MIN, SIGMA_MAX, SIGMA_STEP   = 0.02, 0.90, 5e-4\n",
    "LAMBDA_MIN, LAMBDA_MAX, LAMBDA_STEP= 0.000, 0.300, 5e-4\n",
    "sigma_grid  = np.round(np.arange(SIGMA_MIN,  SIGMA_MAX+1e-12, SIGMA_STEP), 6)\n",
    "lambda_grid = np.round(np.arange(LAMBDA_MIN, LAMBDA_MAX+1e-12, LAMBDA_STEP), 6)\n",
    "\n",
    "rows = []; best_joint = {\"rmse_rel\":float(\"inf\")}\n",
    "for sig in sigma_grid:\n",
    "    Pbs = bs_call_vec(S0,K,T,rr,0.0,float(sig))           # q già gestito come 0 per equity US\n",
    "    Pj  = np.exp(-lambda_grid[None,:]*T[:,None]) * Pbs[:,None]\n",
    "    err = (Pj-Pm[:,None])/den[:,None]\n",
    "    rmse = np.sqrt(np.mean(err*err,axis=0))\n",
    "    mae  = np.mean(np.abs(err),axis=0)\n",
    "    sse  = np.sum(err*err,axis=0)\n",
    "    bias = np.mean(err,axis=0)\n",
    "    for lam, sse_i, rmse_i, mae_i, bias_i in zip(lambda_grid, sse, rmse, mae, bias):\n",
    "        row={\"sigma\":float(sig),\"lambda\":float(lam),\n",
    "             \"sse_rel\":float(sse_i),\"rmse_rel\":float(rmse_i),\n",
    "             \"mae_rel\":float(mae_i),\"bias_rel\":float(bias_i)}\n",
    "        rows.append(row)\n",
    "        if rmse_i < best_joint[\"rmse_rel\"]:\n",
    "            best_joint = row.copy()\n",
    "grid_df = pd.DataFrame(rows).sort_values([\"sigma\",\"lambda\"])\n",
    "grid_df.to_csv(EXPORT/\"grid_relerr_sigma_lambda.csv\", index=False)\n",
    "\n",
    "best_sigma_joint  = float(best_joint[\"sigma\"])\n",
    "best_lambda_joint = float(best_joint[\"lambda\"])\n",
    "\n",
    "# lambda fisso\n",
    "LAMBDA_FIXED = 0.035\n",
    "sigma_scan = np.round(np.arange(SIGMA_MIN, SIGMA_MAX+1e-12, 5e-4), 6)\n",
    "\n",
    "rows2=[]; best_fix={\"rmse_rel\":float(\"inf\")}\n",
    "for sig in sigma_scan:\n",
    "    Pbs = bs_call_vec(S0,K,T,rr,0.0,float(sig))\n",
    "    P   = np.exp(-LAMBDA_FIXED*T)*Pbs\n",
    "    sse,rmse,mae,bias = rel_metrics(P)\n",
    "    row={\"sigma\":float(sig),\"lambda\":LAMBDA_FIXED,\n",
    "         \"sse_rel\":sse,\"rmse_rel\":rmse,\"mae_rel\":mae,\"bias_rel\":bias}\n",
    "    rows2.append(row)\n",
    "    if rmse < best_fix[\"rmse_rel\"]:\n",
    "        best_fix=row.copy()\n",
    "scan_df = pd.DataFrame(rows2).sort_values(\"sigma\")\n",
    "scan_df.to_csv(EXPORT/\"sigma_scan_lambda_fixed_coarse.csv\", index=False)\n",
    "\n",
    "# raffinazione ±0.01\n",
    "s0=best_fix[\"sigma\"]; lo=max(SIGMA_MIN,s0-0.01); hi=min(SIGMA_MAX,s0+0.01)\n",
    "fine = np.round(np.arange(lo, hi+1e-12, 1e-4), 6)\n",
    "\n",
    "rows3=[]; best_fine={\"rmse_rel\":float(\"inf\")}\n",
    "for sig in fine:\n",
    "    Pbs = bs_call_vec(S0,K,T,rr,0.0,float(sig))\n",
    "    P   = np.exp(-LAMBDA_FIXED*T)*Pbs\n",
    "    sse,rmse,mae,bias = rel_metrics(P)\n",
    "    row={\"sigma\":float(sig),\"lambda\":LAMBDA_FIXED,\n",
    "         \"sse_rel\":sse,\"rmse_rel\":rmse,\"mae_rel\":mae,\"bias_rel\":bias}\n",
    "    rows3.append(row)\n",
    "    if rmse < best_fine[\"rmse_rel\"]:\n",
    "        best_fine=row.copy()\n",
    "fine_df = pd.DataFrame(rows3).sort_values(\"sigma\")\n",
    "fine_df.to_csv(EXPORT/\"sigma_scan_lambda_fixed_refined.csv\", index=False)\n",
    "\n",
    "best_sigma_fixed = float(best_fine[\"sigma\"])\n",
    "\n",
    "# diagnostiche\n",
    "P_joint = np.exp(-best_lambda_joint*T) * bs_call_vec(S0,K,T,rr,0.0,best_sigma_joint)\n",
    "pd.DataFrame({\"T\":T,\"K\":K,\"P_mkt\":Pm,\"P_model\":P_joint,\n",
    "              \"rel_resid\":(P_joint-Pm)/den}).to_csv(EXPORT/\"diagnostics_best_joint.csv\", index=False)\n",
    "\n",
    "P_fixed = np.exp(-LAMBDA_FIXED*T) * bs_call_vec(S0,K,T,rr,0.0,best_sigma_fixed)\n",
    "pd.DataFrame({\"T\":T,\"K\":K,\"P_mkt\":Pm,\"P_model\":P_fixed,\n",
    "              \"rel_resid\":(P_fixed-Pm)/den}).to_csv(EXPORT/\"diagnostics_lambda_fixed.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b572c2f-802c-4fa5-9c6b-ee72d62c130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# SECTION 3 — Save calibration JSON for pricing\n",
    "# ======================================================\n",
    "calib_payload = {\n",
    "    \"model\": \"BS-J2D\",\n",
    "    \"ticker\": ticker,\n",
    "    \"S0\": S0,\n",
    "    \"lambda_joint\": best_lambda_joint,\n",
    "    \"sigma_joint\": best_sigma_joint,\n",
    "    \"lambda_fixed\": LAMBDA_FIXED,\n",
    "    \"sigma_star\": best_sigma_fixed,\n",
    "    \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "}\n",
    "with open(EXPORT/\"j2d_calib_lambda_fixed.json\",\"w\") as f:\n",
    "    json.dump(calib_payload, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5922ca1a-0a2c-416f-82ce-662e622ece1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# SECTION 4 — LSMC pricing J2D (hazard + recovery)\n",
    "# ======================================================\n",
    "N_UNIT = 100.0\n",
    "\n",
    "def _bond_spec(tipo: str):\n",
    "    t = str(tipo).upper()\n",
    "    if t==\"2029\":\n",
    "        Cr=0.14872; S_star=N_UNIT/Cr; K_soft=1.3*S_star\n",
    "        return dict(\n",
    "            Cr=Cr, K_soft=K_soft, K_put=N_UNIT,\n",
    "            t_soft_a=_yf(datetime(2026,12,2)),\n",
    "            t_put=_yf(datetime(2028,6,1)),\n",
    "            t_soft_b=_yf(datetime(2029,11,29)),\n",
    "            T=_yf(datetime(2029,11,29)), name=\"2029\"\n",
    "        )\n",
    "    if t in {\"2030\",\"2030B\"}:\n",
    "        Cr=0.23072; S_star=N_UNIT/Cr; K_soft=1.3*S_star\n",
    "        return dict(\n",
    "            Cr=Cr, K_soft=K_soft, K_put=N_UNIT,\n",
    "            t_soft_a=_yf(datetime(2027,3,5)),\n",
    "            t_put=_yf(datetime(2028,3,1)),\n",
    "            t_soft_b=_yf(datetime(2030,2,1)),\n",
    "            T=_yf(datetime(2030,2,27)), name=\"2030B\"\n",
    "        )\n",
    "    raise ValueError(\"tipo deve essere '2029' o '2030B'\")\n",
    "\n",
    "def _next_pow2(n:int)->int: return 1<<(int(n-1).bit_length())\n",
    "def sobol_norm(n:int, d:int, seed=None):\n",
    "    eng=qmc.Sobol(d=d, scramble=True, seed=seed)\n",
    "    n2=_next_pow2(n); U=eng.random_base2(int(np.log2(n2)))[:n]\n",
    "    U=np.clip(U,1e-12,1-1e-12); return norm.ppf(U).astype(np.float64)\n",
    "\n",
    "@nb.njit(fastmath=True)\n",
    "def _rec_annuity_inline(r, lam, tau):\n",
    "    if tau<=0.0: return 0.0\n",
    "    den=r+lam\n",
    "    if den<=0.0: return lam*tau\n",
    "    return (lam/den)*(1.0-np.exp(-den*tau))\n",
    "\n",
    "@nb.njit(parallel=True, fastmath=True)\n",
    "def _front_phase(S0, r, lam, sigma, K_soft, Cr, dt_grid, t_grid, Z, Rrec, Nom):\n",
    "    N1, n_steps = Z.shape\n",
    "    sqrt_dt = np.sqrt(dt_grid); mu = r - 0.5*sigma*sigma\n",
    "    pv_pre = np.zeros(N1); rec_pre = np.zeros(N1); S_put = np.empty(N1)\n",
    "    for i in nb.prange(N1):\n",
    "        s=S0; alive=True; pv=0.0\n",
    "        for k in range(n_steps):\n",
    "            s*=np.exp(mu*dt_grid[k]+sigma*sqrt_dt[k]*Z[i,k])\n",
    "            tau=t_grid[k+1]\n",
    "            if s>K_soft:\n",
    "                pv = np.exp(-(r+lam)*tau)*(Cr*s)\n",
    "                alive=False\n",
    "                break\n",
    "        if alive:\n",
    "            pv_pre[i]=0.0; S_put[i]=s\n",
    "            rec_pre[i]=_rec_annuity_inline(r,lam,t_grid[-1])*Rrec*Nom\n",
    "        else:\n",
    "            pv_pre[i]=pv; S_put[i]=np.nan\n",
    "            rec_pre[i]=_rec_annuity_inline(r,lam,tau)*Rrec*Nom\n",
    "    return pv_pre, rec_pre, S_put\n",
    "\n",
    "@nb.njit(fastmath=True)\n",
    "def _tail_once(s0, r, lam, sigma, K_soft, Cr, Nom, dt_b, dt_T, steps_per_year, z_row, Rrec):\n",
    "    n=max(1, int(np.ceil(max(dt_T,1e-12)*steps_per_year)))\n",
    "    tb=dt_b if dt_b<dt_T else dt_T\n",
    "    mu=r-0.5*sigma*sigma\n",
    "    dt=dt_T/n; sd=np.sqrt(dt)\n",
    "    s=s0; t=0.0\n",
    "    for k in range(n):\n",
    "        s*=np.exp(mu*dt+sigma*sd*z_row[k])\n",
    "        t+=dt\n",
    "        if t<=tb and s>K_soft:\n",
    "            pv   = np.exp(-(r+lam)*t)*(Cr*s)\n",
    "            rec  = _rec_annuity_inline(r,lam,t)*Rrec*Nom\n",
    "            return pv+rec, True, False\n",
    "    payoff = Nom if (Cr*s)<Nom else (Cr*s)\n",
    "    pv   = np.exp(-(r+lam)*dt_T)*payoff\n",
    "    rec  = _rec_annuity_inline(r,lam,dt_T)*Rrec*Nom\n",
    "    return pv+rec, False, True\n",
    "\n",
    "def _basis_log_soft(S,K): \n",
    "    L=np.log(S); soft=np.maximum(np.log(K)-L,0.0)\n",
    "    return np.column_stack([np.ones_like(L),L,L**2,soft])\n",
    "\n",
    "def _fit_cont(S,Y,K):\n",
    "    X=_basis_log_soft(S,K)\n",
    "    beta,_,_,_=np.linalg.lstsq(X,Y,rcond=None)\n",
    "    return X@beta, beta\n",
    "\n",
    "@dataclass\n",
    "class ConvJ2DRes:\n",
    "    price: float; d1: float; d2: float; d3: float; d4: float\n",
    "    beta: np.ndarray\n",
    "\n",
    "def price_J2D_LSMC(S0, r, lam, Rrec, t_a, t_put, t_b, T, K_soft, Cr,\n",
    "                   N1=2**15, sigma=0.6, steps_per_year=252, seed=7) -> ConvJ2DRes:\n",
    "    # front\n",
    "    dt_put = max(0.0, t_put-t_a)\n",
    "    n_front=max(1,int(np.ceil(max(dt_put,1e-12)*steps_per_year)))\n",
    "    t_grid=np.linspace(0.0, dt_put, n_front+1)\n",
    "    dt_grid=np.diff(t_grid)\n",
    "    Zf=sobol_norm(N1, n_front, seed)\n",
    "    pv_pre, rec_pre, S_put_all = _front_phase(S0, r, lam, sigma, K_soft, Cr, dt_grid, t_grid, Zf, Rrec, N_UNIT)\n",
    "    part_front = np.exp(-r*(t_a-0.0))*(pv_pre+rec_pre)\n",
    "\n",
    "    alive=~np.isnan(S_put_all); d1=float((~alive).sum())/N1\n",
    "    S_put=S_put_all[alive].astype(float)\n",
    "    if S_put.size==0:\n",
    "        return ConvJ2DRes(price=float(part_front.mean()), d1=d1, d2=0.0, d3=0.0, d4=0.0, beta=np.full(4,np.nan))\n",
    "\n",
    "    # tail\n",
    "    dt_b_rel=max(0.0,t_b-t_put); dt_T_rel=max(0.0,T-t_put)\n",
    "    n_tail=max(1,int(np.ceil(max(dt_T_rel,1e-12)*steps_per_year)))\n",
    "    Zt=sobol_norm(S_put.size, n_tail, seed+777)\n",
    "    V=np.empty_like(S_put); hit=np.zeros(S_put.size,bool); reach=np.zeros(S_put.size,bool)\n",
    "    for i in range(S_put.size):\n",
    "        v,h,rch=_tail_once(S_put[i], r, lam, sigma, K_soft, Cr, N_UNIT, dt_b_rel, dt_T_rel, steps_per_year, Zt[i], Rrec)\n",
    "        V[i]=v; hit[i]=h; reach[i]=rch\n",
    "    Chat, beta = _fit_cont(S_put, V, K_soft)\n",
    "    threshold=N_UNIT\n",
    "    V_dec=np.maximum(threshold, Chat)\n",
    "    d2=float((V_dec==threshold).sum())/N1\n",
    "    surv=np.exp(-lam*dt_put)\n",
    "    part_put=np.exp(-r*(t_put-t_a))*surv*V_dec\n",
    "    price=float(part_front.sum()+part_put.sum())/N1\n",
    "    d3=float(hit.sum())/N1; d4=float(reach.sum())/N1\n",
    "    return ConvJ2DRes(price, d1,d2,d3,d4, beta)\n",
    "\n",
    "def r_from_curve(T: float) -> float:\n",
    "    return r_curve(float(T))\n",
    "\n",
    "def run_bond(tipo, sigma_best, lam_fixed, Rrec):\n",
    "    spec=_bond_spec(tipo)\n",
    "    r_T = r_from_curve(float(spec[\"T\"]))\n",
    "    res = price_J2D_LSMC(S0=S0, r=r_T, lam=lam_fixed, Rrec=Rrec,\n",
    "                         t_a=spec[\"t_soft_a\"], t_put=spec[\"t_put\"],\n",
    "                         t_b=spec[\"t_soft_b\"], T=spec[\"T\"],\n",
    "                         K_soft=spec[\"K_soft\"], Cr=spec[\"Cr\"],\n",
    "                         N1=2**15, sigma=sigma_best, seed=42)\n",
    "    return spec, r_T, res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b4c8313-60a9-467d-8bb1-afc058752341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output scritto in: C:\\Users\\salvm\\Desktop\\UNI\\jupyter\\export\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# SECTION 5 — Run and save results\n",
    "# ======================================================\n",
    "best_sigma = best_sigma_fixed\n",
    "lam_used   = LAMBDA_FIXED\n",
    "\n",
    "rows=[]\n",
    "for Rrec in (0.00, 0.15, 0.30):\n",
    "    for tipo in (\"2029\",\"2030B\"):\n",
    "        spec, rT, res = run_bond(tipo, best_sigma, lam_used, Rrec)\n",
    "        rows.append({\n",
    "            \"bond\": spec[\"name\"], \"Rrec\": Rrec, \"r_T\": rT,\n",
    "            \"price\": res.price, \"d1\":res.d1, \"d2\":res.d2, \"d3\":res.d3, \"d4\":res.d4,\n",
    "            \"beta0\":res.beta[0], \"beta1\":res.beta[1], \"beta2\":res.beta[2], \"beta3\":res.beta[3]\n",
    "        })\n",
    "res_df = pd.DataFrame(rows)\n",
    "res_df.to_csv(EXPORT/\"convertible_J2D_results.csv\", index=False)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.scatter(K, (P_fixed-Pm)/den, s=10)\n",
    "plt.axhline(0,color=\"k\",lw=0.6)\n",
    "plt.title(f\"{ticker} rel residuals (lambda={lam_used:.3f}, sigma={best_sigma:.3f})\")\n",
    "plt.xlabel(\"Strike\"); plt.ylabel(\"Relative residual\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(EXPORT/\"rel_residuals_fit.png\", dpi=160)\n",
    "plt.close()\n",
    "\n",
    "print(\"Output scritto in:\", EXPORT.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0948027b-a630-41df-b579-ba1b4ac7c1a4",
   "metadata": {},
   "source": [
    "## best fit vs fixed fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "090a023a-a43c-4c4d-844b-b8ddf3004c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST (lambda fixed=0.035): sigma=0.668500  RMSE_rel=9.213967e-02\n",
      "BEST (sigma, lambda free): sigma=0.672500  lambda=0.049000  RMSE_rel=9.140127e-02\n"
     ]
    }
   ],
   "source": [
    "# Best-fit summary: BS + jump-to-default\n",
    "# Prints:\n",
    "#  - best sigma with lambda fixed=0.035 and its relative RMSE\n",
    "#  - best (sigma, lambda) with both free and its relative RMSE\n",
    "\n",
    "import json, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# ---------- I/O ----------\n",
    "CHAIN_FILE = \"chain_data.csv\"\n",
    "META_FILE  = \"mstr_panel_meta.json\"\n",
    "LAMBDA_FIXED = 0.035\n",
    "EXPORT = Path(\"export\"); EXPORT.mkdir(exist_ok=True)\n",
    "\n",
    "# ---------- NSS (OLS) ----------\n",
    "def _nss_basis(m, tau1, tau2):\n",
    "    m = np.asarray(m, float)\n",
    "    def B1(x,t):\n",
    "        xt = x/t; den = np.where(xt==0.0, 1.0, xt)\n",
    "        return (1.0 - np.exp(-xt)) / den\n",
    "    def B2(x,t):\n",
    "        xt = x/t; den = np.where(xt==0.0, 1.0, xt)\n",
    "        return (1.0 - np.exp(-xt)) / den - np.exp(-xt)\n",
    "    return B1(m, tau1), B2(m, tau1), B2(m, tau2)\n",
    "\n",
    "def calibrate_nss_ols(maturities, y):\n",
    "    maturities = np.asarray(maturities, float)\n",
    "    y = np.asarray(y, float)\n",
    "    def obj(z):\n",
    "        t1, t2 = np.exp(z[0]), np.exp(z[1])\n",
    "        B1,B2,B3 = _nss_basis(maturities, t1, t2)\n",
    "        X = np.column_stack([np.ones_like(maturities), B1, B2, B3])\n",
    "        beta, *_ = np.linalg.lstsq(X, y, rcond=None)\n",
    "        r = y - X @ beta\n",
    "        return float(r @ r)\n",
    "    z0 = np.log([1.5, 3.0])\n",
    "    res = minimize(obj, z0, method=\"Nelder-Mead\")\n",
    "    t1, t2 = np.exp(res.x[0]), np.exp(res.x[1])\n",
    "    B1,B2,B3 = _nss_basis(maturities, t1, t2)\n",
    "    X = np.column_stack([np.ones_like(maturities), B1, B2, B3])\n",
    "    beta, *_ = np.linalg.lstsq(X, y, rcond=None)\n",
    "    def yld(m):\n",
    "        m = np.asarray(m, float)\n",
    "        b1,b2,b3 = _nss_basis(m, t1, t2)\n",
    "        Xm = np.column_stack([np.ones_like(m), b1, b2, b3])\n",
    "        return Xm @ beta\n",
    "    return yld\n",
    "\n",
    "# fixed input curve (levels in %)\n",
    "_y_m = np.array([1/12, 1.5/12, 2/12, 3/12, 4/12, 6/12, 1, 2, 3, 5, 7, 10, 20, 30])\n",
    "_y_y = np.array([4.18, 4.15, 4.08, 4.00, 3.95, 3.79, 3.56, 3.46, 3.47, 3.59, 3.78, 4.02, 4.58, 4.60])/100\n",
    "nss_yield = calibrate_nss_ols(_y_m, _y_y)\n",
    "r_curve = lambda T: float(np.asarray(nss_yield(np.array([T])))[0])\n",
    "\n",
    "# ---------- meta ----------\n",
    "with open(META_FILE, \"r\") as f:\n",
    "    meta = json.load(f)\n",
    "S0 = float(meta.get(\"S0\", 100.0))\n",
    "q  = float(meta.get(\"q\", 0.0))  # usually 0 for US equities\n",
    "spot_ts = meta.get(\"spot_ts\")\n",
    "BASE_DATE = datetime.fromisoformat(spot_ts.replace(\"Z\",\"+00:00\")).astimezone(timezone.utc).replace(tzinfo=None)\n",
    "\n",
    "# ---------- data ----------\n",
    "df = pd.read_csv(CHAIN_FILE)\n",
    "lc = {c.lower(): c for c in df.columns}\n",
    "def pick(cands):\n",
    "    for c in cands:\n",
    "        if c in lc: return lc[c]\n",
    "    return None\n",
    "\n",
    "colT = pick([\"maturity\",\"t\",\"tau\",\"ttm\",\"time_to_maturity\"])\n",
    "colK = pick([\"strike\",\"k\",\"strk\",\"strikeprice\",\"strike_price\"])\n",
    "colP = pick([\"price\",\"mid\",\"mark\",\"close\",\"last\",\"theo\",\"settlement\",\"settle\"])\n",
    "\n",
    "if colT is None or colK is None or colP is None:\n",
    "    raise KeyError(\"Serve avere colonne per maturity, strike, price.\")\n",
    "\n",
    "df = df[[colT, colK, colP]].rename(columns={colT:\"T\", colK:\"K\", colP:\"close\"})\n",
    "df = df.apply(pd.to_numeric, errors=\"coerce\").dropna()\n",
    "df = df[(df[\"T\"]>0) & (df[\"K\"]>0) & (df[\"close\"]>0)]\n",
    "df = df[df[\"close\"]>=1.0].copy()\n",
    "df[\"r\"] = df[\"T\"].apply(r_curve)\n",
    "df = df.sort_values([\"T\",\"K\"]).reset_index(drop=True)\n",
    "\n",
    "K  = df[\"K\"].values.astype(float)\n",
    "T  = df[\"T\"].values.astype(float)\n",
    "rT = df[\"r\"].values.astype(float)\n",
    "Pm = df[\"close\"].values.astype(float)\n",
    "DEN = np.maximum(Pm, 1e-12)\n",
    "\n",
    "# ---------- Black–Scholes vectorized ----------\n",
    "def bs_call_vec(S0, K, T, r, q, sigma):\n",
    "    K = np.asarray(K,float); T=np.asarray(T,float); r=np.asarray(r,float); s=float(sigma); q=float(q)\n",
    "    sqrtT = np.sqrt(np.maximum(T, 0.0))\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        d1 = (np.log(S0/K) + (r - q + 0.5*s*s)*T) / (s*sqrtT)\n",
    "    d1 = np.where((s<=0) | (T<=0), np.inf, d1)\n",
    "    d2 = d1 - s*sqrtT\n",
    "    price = S0*np.exp(-q*T)*norm.cdf(d1) - K*np.exp(-r*T)*norm.cdf(d2)\n",
    "    intrinsic = np.maximum(S0 - K, 0.0)\n",
    "    return np.where(T<=0, intrinsic, price)\n",
    "\n",
    "def rmse_rel(model):\n",
    "    e = (model - Pm)/DEN\n",
    "    return float(np.sqrt(np.mean(e*e)))\n",
    "\n",
    "# ---------- search joint (sigma, lambda) ----------\n",
    "SIGMA_MIN, SIGMA_MAX, SIGMA_STEP   = 0.02, 0.90, 5e-4\n",
    "LAMBDA_MIN, LAMBDA_MAX, LAMBDA_STEP= 0.000, 0.300, 5e-4\n",
    "sigma_grid  = np.round(np.arange(SIGMA_MIN,  SIGMA_MAX+1e-12, SIGMA_STEP), 6)\n",
    "lambda_grid = np.round(np.arange(LAMBDA_MIN, LAMBDA_MAX+1e-12, LAMBDA_STEP), 6)\n",
    "\n",
    "best_joint = {\"sigma\":None,\"lambda\":None,\"rmse_rel\":np.inf}\n",
    "for sig in sigma_grid:\n",
    "    Pbs = bs_call_vec(S0, K, T, rT, q, sig)\n",
    "    P   = np.exp(-lambda_grid[None,:]*T[:,None]) * Pbs[:,None]\n",
    "    e   = (P - Pm[:,None]) / DEN[:,None]\n",
    "    rmse = np.sqrt(np.mean(e*e, axis=0))\n",
    "    j = int(np.argmin(rmse))\n",
    "    if float(rmse[j]) < best_joint[\"rmse_rel\"]:\n",
    "        best_joint = {\"sigma\": float(sig), \"lambda\": float(lambda_grid[j]), \"rmse_rel\": float(rmse[j])}\n",
    "\n",
    "# ---------- search sigma with lambda fixed ----------\n",
    "# coarse then fine around min\n",
    "coarse = sigma_grid\n",
    "rmse_c = []\n",
    "for sig in coarse:\n",
    "    P = np.exp(-LAMBDA_FIXED*T) * bs_call_vec(S0, K, T, rT, q, sig)\n",
    "    rmse_c.append(rmse_rel(P))\n",
    "i0 = int(np.argmin(rmse_c)); s0 = float(coarse[i0])\n",
    "lo, hi = max(SIGMA_MIN, s0-0.01), min(SIGMA_MAX, s0+0.01)\n",
    "fine = np.round(np.arange(lo, hi+1e-12, 1e-4), 6)\n",
    "\n",
    "best_fix = {\"sigma\":None,\"rmse_rel\":np.inf}\n",
    "for sig in fine:\n",
    "    P = np.exp(-LAMBDA_FIXED*T) * bs_call_vec(S0, K, T, rT, q, sig)\n",
    "    r_ = rmse_rel(P)\n",
    "    if r_ < best_fix[\"rmse_rel\"]:\n",
    "        best_fix = {\"sigma\": float(sig), \"rmse_rel\": float(r_)}\n",
    "\n",
    "# ---------- print ----------\n",
    "print(f\"BEST (lambda fixed={LAMBDA_FIXED:.3f}): sigma={best_fix['sigma']:.6f}  RMSE_rel={best_fix['rmse_rel']:.6e}\")\n",
    "print(f\"BEST (sigma, lambda free): sigma={best_joint['sigma']:.6f}  lambda={best_joint['lambda']:.6f}  RMSE_rel={best_joint['rmse_rel']:.6e}\")\n",
    "\n",
    "# optional saves\n",
    "pd.DataFrame([{\n",
    "    \"lambda_fixed\": LAMBDA_FIXED,\n",
    "    \"sigma_fixed\": best_fix[\"sigma\"],\n",
    "    \"rmse_rel_fixed\": best_fix[\"rmse_rel\"],\n",
    "    \"sigma_joint\": best_joint[\"sigma\"],\n",
    "    \"lambda_joint\": best_joint[\"lambda\"],\n",
    "    \"rmse_rel_joint\": best_joint[\"rmse_rel\"],\n",
    "}]).to_csv(EXPORT/\"bestfit_summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc724db-cec7-46dd-b7a4-f18928e6acad",
   "metadata": {},
   "source": [
    "## heston j2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f139da0-9a96-4320-847d-162ae0190d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Heston J2D convertible pricing — two cases and CSV export\n",
    "# Cases:\n",
    "#   1) \"lambda libero\"  -> use params in mstr_panel_heston_params_default_fixed.json\n",
    "#   2) \"lambda fisso\"   -> use params in mstr_panel_heston_params_default.json\n",
    "# Recovery rates: 0.00, 0.15, 0.30\n",
    "# Output: export/convertible_hestonJ2D_result.csv\n",
    "# ============================================================\n",
    "\n",
    "import os, json, math\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "from scipy.stats import qmc, norm\n",
    "from scipy.optimize import minimize\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# ---------- paths ----------\n",
    "EXPORT = Path(\"export\"); EXPORT.mkdir(parents=True, exist_ok=True)\n",
    "META_FILE = \"mstr_panel_meta.json\"\n",
    "HPARAMS_FREE   = \"mstr_panel_heston_params_default_fixed.json\"  # lambda libero\n",
    "HPARAMS_FIXED  = \"mstr_panel_heston_params_default.json\"        # lambda fisso\n",
    "\n",
    "# ---------- base meta ----------\n",
    "with open(META_FILE, \"r\") as f:\n",
    "    meta = json.load(f)\n",
    "S0_meta  = float(meta.get(\"S0\", 100.0))\n",
    "spot_ts  = meta.get(\"spot_ts\")\n",
    "BASE_DATE = datetime.fromisoformat(spot_ts.replace(\"Z\",\"+00:00\")).astimezone(timezone.utc).replace(tzinfo=None)\n",
    "\n",
    "def _yf(d: datetime, base: datetime = BASE_DATE) -> float:\n",
    "    return (d - base).days/365.0\n",
    "\n",
    "# ---------- NSS curve (OLS) ----------\n",
    "def _nss_basis(m, tau1, tau2):\n",
    "    m = np.asarray(m, float)\n",
    "    def B1(x,t):\n",
    "        xt = x/t; den = np.where(xt==0.0, 1.0, xt)\n",
    "        return (1.0 - np.exp(-xt)) / den\n",
    "    def B2(x,t):\n",
    "        xt = x/t; den = np.where(xt==0.0, 1.0, xt)\n",
    "        return (1.0 - np.exp(-xt)) / den - np.exp(-xt)\n",
    "    return B1(m,tau1), B2(m,tau1), B2(m,tau2)\n",
    "\n",
    "def calibrate_nss_ols(maturities, y):\n",
    "    maturities = np.asarray(maturities, float)\n",
    "    y = np.asarray(y, float)\n",
    "    def obj(z):\n",
    "        t1, t2 = np.exp(z[0]), np.exp(z[1])\n",
    "        B1,B2,B3 = _nss_basis(maturities, t1, t2)\n",
    "        X = np.column_stack([np.ones_like(maturities), B1, B2, B3])\n",
    "        beta, *_ = np.linalg.lstsq(X, y, rcond=None)\n",
    "        r = y - X @ beta\n",
    "        return float(r @ r)\n",
    "    z0 = np.log([1.5, 3.0])\n",
    "    res = minimize(obj, z0, method=\"Nelder-Mead\")\n",
    "    t1, t2 = np.exp(res.x[0]), np.exp(res.x[1])\n",
    "    B1,B2,B3 = _nss_basis(maturities, t1, t2)\n",
    "    X = np.column_stack([np.ones_like(maturities), B1, B2, B3])\n",
    "    beta, *_ = np.linalg.lstsq(X, y, rcond=None)\n",
    "    def yld(m):\n",
    "        m = np.asarray(m, float)\n",
    "        b1,b2,b3 = _nss_basis(m, t1, t2)\n",
    "        Xm = np.column_stack([np.ones_like(m), b1, b2, b3])\n",
    "        return Xm @ beta\n",
    "    return yld\n",
    "\n",
    "yield_m = np.array([1/12, 1.5/12, 2/12, 3/12, 4/12, 6/12, 1, 2, 3, 5, 7, 10, 20, 30])\n",
    "yield_y = np.array([4.18, 4.15, 4.08, 4.00, 3.95, 3.79, 3.56, 3.46, 3.47, 3.59, 3.78, 4.02, 4.58, 4.60])/100\n",
    "nss_yield = calibrate_nss_ols(yield_m, yield_y)\n",
    "r_curve = lambda T: float(np.asarray(nss_yield(np.array([T])))[0])\n",
    "\n",
    "# ---------- bond specs (per nominale 100) ----------\n",
    "N_UNIT = 100.0\n",
    "def bond_spec(tipo: str):\n",
    "    t = str(tipo).strip().upper()\n",
    "    if t == \"2029\":\n",
    "        Cr=0.14872; S_star=N_UNIT/Cr; K_soft=1.3*S_star\n",
    "        return dict(\n",
    "            Cr=Cr, K_soft=K_soft, K_put=N_UNIT,\n",
    "            t_a=_yf(datetime(2026,12,2)),\n",
    "            t_put=_yf(datetime(2028,6,1)),\n",
    "            t_b=_yf(datetime(2029,11,29)),\n",
    "            T=_yf(datetime(2029,11,29)),\n",
    "            name=\"2029\"\n",
    "        )\n",
    "    if t in {\"2030\",\"2030B\"}:\n",
    "        Cr=0.23072; S_star=N_UNIT/Cr; K_soft=1.3*S_star\n",
    "        return dict(\n",
    "            Cr=Cr, K_soft=K_soft, K_put=N_UNIT,\n",
    "            t_a=_yf(datetime(2027,3,5)),\n",
    "            t_put=_yf(datetime(2028,3,1)),\n",
    "            t_b=_yf(datetime(2030,2,1)),\n",
    "            T=_yf(datetime(2030,2,27)),\n",
    "            name=\"2030B\"\n",
    "        )\n",
    "    raise ValueError(\"tipo deve essere '2029' o '2030B'\")\n",
    "\n",
    "# ---------- Heston simulator (Sobol, log-Euler full truncation) ----------\n",
    "def sobol_norm(n_paths, dim, seed=None):\n",
    "    eng = qmc.Sobol(d=dim, scramble=True, seed=seed)\n",
    "    # use power-of-two for balance\n",
    "    p = int(np.ceil(np.log2(max(n_paths,1))))\n",
    "    U = eng.random_base2(p)[:n_paths]\n",
    "    U = np.clip(U, 1e-12, 1-1e-12)\n",
    "    return norm.ppf(U).astype(np.float64)\n",
    "\n",
    "def simulate_heston_qmc(S0, v0, r, q, kappa, theta, xi, rho, t_grid, n_paths, seed=None):\n",
    "    t_grid = np.asarray(t_grid, float)\n",
    "    dt = np.diff(t_grid); m = len(dt)\n",
    "    S = np.empty((n_paths, m+1), dtype=float)\n",
    "    V = np.empty((n_paths, m+1), dtype=float)\n",
    "    S[:,0] = float(S0); V[:,0] = float(v0)\n",
    "    Z = sobol_norm(n_paths, 2*m, seed=seed).reshape(n_paths, m, 2)\n",
    "    Z1, Z2 = Z[:,:,0], Z[:,:,1]\n",
    "    mu = float(r - q)\n",
    "    for i in range(m):\n",
    "        Vi = np.maximum(V[:,i], 0.0)\n",
    "        sqrtVi = np.sqrt(Vi)\n",
    "        dW2 = (rho*Z1[:,i] + np.sqrt(max(1.0-rho*rho,0.0))*Z2[:,i]) * np.sqrt(dt[i])\n",
    "        dW1 = Z1[:,i]*np.sqrt(dt[i])\n",
    "        V[:,i+1] = np.maximum(V[:,i] + kappa*(theta - Vi)*dt[i] + xi*sqrtVi*dW2, 0.0)\n",
    "        S[:,i+1] = S[:,i] * np.exp((mu - 0.5*Vi)*dt[i] + sqrtVi*dW1)\n",
    "    return S, V\n",
    "\n",
    "# ---------- LSMC with hazard λ and recovery R ----------\n",
    "def rec_annuity(r, lam, tau):\n",
    "    if tau <= 0: return 0.0\n",
    "    den = r + lam\n",
    "    if den <= 0: return lam*tau\n",
    "    return (lam/den)*(1.0 - math.exp(-den*tau))\n",
    "\n",
    "def basis_log_soft(S, K_soft):\n",
    "    L = np.log(S); soft = np.maximum(np.log(K_soft) - L, 0.0)\n",
    "    return np.column_stack([np.ones_like(L), L, L**2, soft])\n",
    "\n",
    "def price_convertible_heston_J2D(S0, v0, kappaQ, thetaQ, xi, rho, r, q, lam, Rrec,\n",
    "                                 t_a, t_put, t_b, T, K_soft, Cr,\n",
    "                                 n_paths=2**15, steps_per_year=252, seed=7):\n",
    "    # timeline\n",
    "    dt_put = max(0.0, t_put - t_a)\n",
    "    m_front = max(1, int(np.ceil(max(dt_put,1e-12)*steps_per_year)))\n",
    "    t_front = np.linspace(0.0, dt_put, m_front+1)\n",
    "    # simulate to t_put\n",
    "    S, V = simulate_heston_qmc(S0, v0, r, q, kappaQ, thetaQ, xi, rho, t_front, n_paths, seed)\n",
    "    # early soft-call before t_put\n",
    "    called = np.zeros(n_paths, dtype=bool)\n",
    "    pv_pre = np.zeros(n_paths, dtype=float)\n",
    "    rec_pre= np.zeros(n_paths, dtype=float)\n",
    "    for i in range(n_paths):\n",
    "        s_path = S[i]\n",
    "        hit_j = np.argmax(s_path[1:] >= K_soft) + 1 if np.any(s_path[1:] >= K_soft) else -1\n",
    "        if hit_j > 0:\n",
    "            tau = t_front[hit_j]\n",
    "            pv_pre[i]  = math.exp(-(r+lam)*tau) * (Cr * s_path[hit_j])\n",
    "            rec_pre[i] = rec_annuity(r, lam, tau) * Rrec * N_UNIT\n",
    "            called[i] = True\n",
    "        else:\n",
    "            rec_pre[i] = rec_annuity(r, lam, t_front[-1]) * Rrec * N_UNIT\n",
    "    S_put = S[~called, -1]\n",
    "    V_put = V[~called, -1]\n",
    "    part_front = np.exp(-r*(t_a-0.0)) * (pv_pre + rec_pre)\n",
    "    d1 = called.mean()\n",
    "\n",
    "    if S_put.size == 0:\n",
    "        return float(part_front.mean()), d1, 0.0, 0.0, 0.0, np.full(4, np.nan)\n",
    "\n",
    "    # tail [t_put, T]\n",
    "    dt_b = max(0.0, t_b - t_put)\n",
    "    dt_T = max(0.0, T   - t_put)\n",
    "    m_tail = max(1, int(np.ceil(max(dt_T,1e-12)*steps_per_year)))\n",
    "    t_tail = np.linspace(0.0, dt_T, m_tail+1)\n",
    "    S_tail, _ = simulate_heston_qmc(S_put, V_put, r, q, kappaQ, thetaQ, xi, rho, t_tail, len(S_put), seed+999)\n",
    "\n",
    "    # pathwise payoff with hazard and recovery\n",
    "    Y = np.empty(S_put.size, float)\n",
    "    hit_post = np.zeros(S_put.size, bool)\n",
    "    reach_T  = np.zeros(S_put.size, bool)\n",
    "    for i in range(S_put.size):\n",
    "        s_path = S_tail[i]\n",
    "        # first soft call before t_b\n",
    "        idx = np.argmax(s_path[1:] >= K_soft) + 1 if np.any(s_path[1:] >= K_soft) else -1\n",
    "        if idx > 0 and t_tail[idx] <= min(dt_b, dt_T):\n",
    "            tau = t_tail[idx]\n",
    "            pay = math.exp(-(r+lam)*tau) * (Cr * s_path[idx])\n",
    "            rec = rec_annuity(r, lam, tau) * Rrec * N_UNIT\n",
    "            Y[i] = pay + rec\n",
    "            hit_post[i] = True\n",
    "        else:\n",
    "            # at maturity\n",
    "            sT  = s_path[-1]\n",
    "            pay = math.exp(-(r+lam)*dt_T) * max(N_UNIT, Cr * sT)\n",
    "            rec = rec_annuity(r, lam, dt_T) * Rrec * N_UNIT\n",
    "            Y[i] = pay + rec\n",
    "            reach_T[i] = True\n",
    "\n",
    "    # LSMC at t_put\n",
    "    X = basis_log_soft(S_put, K_soft)\n",
    "    beta, *_ = np.linalg.lstsq(X, Y, rcond=None)\n",
    "    Chat = X @ beta\n",
    "    threshold = N_UNIT\n",
    "    V_dec = np.maximum(threshold, Chat)\n",
    "\n",
    "    d2 = (V_dec == threshold).sum() / float(n_paths)     # per N_paths, come d1\n",
    "    d3 = hit_post.sum() / float(n_paths)\n",
    "    d4 = reach_T.sum() / float(n_paths)\n",
    "\n",
    "    surv_put = math.exp(-lam * dt_put)\n",
    "    part_put = np.exp(-r*(t_put - t_a)) * surv_put * V_dec\n",
    "    price = (part_front.sum() + part_put.sum()) / float(n_paths)\n",
    "    return float(price), float(d1), float(d2), float(d3), float(d4), beta\n",
    "\n",
    "# ---------- load Heston JSON helper ----------\n",
    "def load_heston_params(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        hp = json.load(f)\n",
    "    root = hp.get(\"root\", hp)\n",
    "    S0   = float(root.get(\"S0\", S0_meta))\n",
    "    v0   = float(root[\"v0\"])\n",
    "    kQ   = float(root[\"kappaQ\"])\n",
    "    tQ   = float(root[\"thetaQ\"])\n",
    "    xi   = float(root[\"xi\"])\n",
    "    rho  = float(root[\"rho\"])\n",
    "    lam  = float(root.get(\"lambda\", 0.0))\n",
    "    return S0, v0, kQ, tQ, xi, rho, lam\n",
    "\n",
    "# ---------- run both cases ----------\n",
    "cases = [\n",
    "    (\"heston_lambda_libero\", HPARAMS_FREE,  True),   # usa lambda del file\n",
    "    (\"heston_lambda_fisso\",  HPARAMS_FIXED, True),   # usa lambda del file come fisso\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for case_name, fpath, use_file_lambda in cases:\n",
    "    S0_h, v0, kQ, tQ, xi, rho, lam_file = load_heston_params(fpath)\n",
    "    S0_use = S0_h if np.isfinite(S0_h) else S0_meta\n",
    "    for tipo in (\"2029\",\"2030B\"):\n",
    "        spec = bond_spec(tipo)\n",
    "        r_T = r_curve(float(spec[\"T\"]))\n",
    "        for Rrec in (0.00, 0.15, 0.30):\n",
    "            price, d1, d2, d3, d4, beta = price_convertible_heston_J2D(\n",
    "                S0=S0_use, v0=v0, kappaQ=kQ, thetaQ=tQ, xi=xi, rho=rho,\n",
    "                r=r_T, q=0.0, lam=lam_file, Rrec=Rrec,\n",
    "                t_a=spec[\"t_a\"], t_put=spec[\"t_put\"], t_b=spec[\"t_b\"], T=spec[\"T\"],\n",
    "                K_soft=spec[\"K_soft\"], Cr=spec[\"Cr\"],\n",
    "                n_paths=2**15, steps_per_year=252, seed=7\n",
    "            )\n",
    "            rows.append({\n",
    "                \"case\": case_name,\n",
    "                \"file\": fpath,\n",
    "                \"bond\": spec[\"name\"],\n",
    "                \"S0\": S0_use,\n",
    "                \"r_T\": r_T,\n",
    "                \"lambda\": lam_file,\n",
    "                \"Rrec\": Rrec,\n",
    "                \"price\": price,\n",
    "                \"d1\": d1, \"d2\": d2, \"d3\": d3, \"d4\": d4,\n",
    "                \"beta0\": float(beta[0]), \"beta1\": float(beta[1]),\n",
    "                \"beta2\": float(beta[2]), \"beta3\": float(beta[3]),\n",
    "            })\n",
    "\n",
    "# ---------- save CSV ----------\n",
    "outdf = np.array(rows, dtype=object)\n",
    "import pandas as pd\n",
    "df_out = pd.DataFrame(rows)\n",
    "df_out.to_csv(EXPORT/\"convertible_hestonJ2D_result.csv\", index=False)\n",
    "print(EXPORT/\"convertible_hestonJ2D_result.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
